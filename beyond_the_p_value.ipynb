{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Rmd_chunk_options": "setup",
    "autoscroll": false,
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "library(tidyverse)\n",
    "library(infer)\n",
    "library(readxl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## P-value: Living in the world of the null hypothesis\n",
    "\n",
    "I tried to bend a quarter to make it \"unfair\" and yield tails more often. Did I succeed?\n",
    "\n",
    "$$ H_0: p = 0.5$$\n",
    "$$H_A: p < 0.5$$\n",
    "\n",
    "Let's say I flip it 5 times and got heads only once.  How unusual is that under the null hypothesis? We can easily simulate this in R using the `infer` package:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Rmd_chunk_options": "test_heads",
    "autoscroll": false,
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Number of heads. Change this to see what happens!\n",
    "number_heads = 1\n",
    "n = 5\n",
    "observed_p = number_heads/n\n",
    "\n",
    "## Enter data\n",
    "my_data = data.frame(heads = c(rep(FALSE, n - number_heads),\n",
    "                               rep(TRUE, number_heads)))\n",
    "\n",
    "null_heads = my_data %>%\n",
    "  specify(response = heads, success = \"TRUE\") %>%\n",
    "  hypothesize(\"point\", p = 0.5) %>%\n",
    "  generate(reps = 1000, type = \"simulate\") %>%\n",
    "  calculate(stat = \"prop\")\n",
    "\n",
    "visualise(null_heads) +\n",
    "  shade_pvalue(observed_p, direction = \"less\")\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "null_heads %>%\n",
    "  get_pvalue(observed_p, direction = \"less\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Experiment 1 data\n",
    "\n",
    "`exp1.xlsx` contains 100 subjects who took the ESP test (tried to guess which curtain the picture was behind).  During each session, some of the pictures were erotic and some were non-erotic.\n",
    "\n",
    "Variables are as follows:\n",
    "\n",
    "  - *Session* Order in which participant was seen.\n",
    "  - *Session_Type* (Added EB) Some participants saw different combinations of stimuli.  This is my best guess from Bem's writing about which was which.\n",
    "  - *Num_Erotic* (Added EB) Number of erotic trials, varies by session type; my best guess.\n",
    "  - *Num_Control* (Added EB) Number of control trials, varies by session type; my best guess.\n",
    "  - *Erotic.Hits.PC* Percentage correct on erotic trials\n",
    "  - *Control.Hits.PC* Percentage correct on control trials\n",
    "  - *Stimulus.Seeking* 1-5 scale on how \"stimulus-seeking\" the participant is\n",
    "  - *Date*\n",
    "  - *StartTime*\n",
    "  - *Session.Length*\n",
    "  - *Participant.Sex*\n",
    "  - *Participant.Age*\n",
    "  - *ExpSex* ?\n",
    "\n",
    "Below is code for reading in all trials, calculating the overall hit rate, and testing whether it is significantly different from chance:\n",
    "\n",
    "$$ H_0 = \\mu_\\text{hit rate} = 50$$\n",
    "$$ H_A = \\mu_\\text{hit rate} > 50$$\n",
    "What did we actually see on average?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Original source: https://replicationindex.files.wordpress.com/2018/01/exp1.xlsx\n",
    "# Some variables added as noted above.\n",
    "\n",
    "exp1 = read_excel(\"exp1.xlsx\")\n",
    "\n",
    "exp1_all_hits = exp1 %>%\n",
    "  mutate(All.Hits.PC = (Erotic.Hits.PC * Num_Erotic + Control.Hits.PC * Num_Control) * 100/(Num_Erotic + Num_Control))\n",
    "\n",
    "all_hits_mean = exp1_all_hits %>%\n",
    "    specify(response = All.Hits.PC) %>%\n",
    "    calculate(stat = \"mean\")\n",
    "\n",
    "all_hits_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "null_all_hits = exp1_all_hits %>%\n",
    "  specify(response = All.Hits.PC) %>%\n",
    "  hypothesize(null = \"point\", mu = 50) %>%\n",
    "  generate(reps = 1000, type = \"bootstrap\") %>%\n",
    "  calculate(stat = \"mean\")\n",
    "\n",
    "visualize(null_all_hits) +\n",
    "  shade_pvalue(all_hits_mean, direction = \"greater\")\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "null_all_hits %>%\n",
    "  get_pvalue(all_hits_mean, direction = \"greater\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We can also do a good old-fashioned t-test, for a similar result:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t.test(exp1_all_hits$All.Hits.PC, mu = 50, alternative = \"greater\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Can you find any significant findings here?\n",
    "\n",
    "\n",
    "\n",
    "## Preregistration\n",
    "- Preregister on Open Science\n",
    "\n",
    "\n",
    "## Visual hypothesis testing -- the line-up\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "Rmd_header": {
   "output": "html_notebook",
   "title": "Beyond the P-Value: Visualizing and Embracing Uncertainty"
  },
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
